---
title: Создание инференса для использования в Managed RAG
source: Cloud.ru Evolution Tutorials
url: https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference
topic: ai-factory
---
# Создание инференса для использования в Managed RAG

С помощью этого руководства вы последовательно создадите три типа инференса в ML Inference для использования их в базе знаний Managed RAG, затем проверите работоспособность базы знаний.

Вы будете использовать следующие сервисы:

- [Evolution Managed RAG](https://cloud.ru/docs/rag/ug/index)Evolution Managed RAG — сервис для создания и управления базами знаний, используемыми при генерации ответов языковыми моделями.
- [Evolution Object Storage](https://cloud.ru/docs/s3e/ug/index)Evolution Object Storage — объектное хранилище для размещения документов, из которых будет формироваться база знаний.
- [Evolution ML Inference](https://cloud.ru/docs/ml-inference/ug/index)Evolution ML Inference — сервис для запуска ML-моделей в облаке.
- [Huggingface](https://huggingface.co/)Huggingface — платформа для публикации и использования моделей машинного обучения.

[Evolution Managed RAG](https://cloud.ru/docs/rag/ug/index)Evolution Managed RAG — сервис для создания и управления базами знаний, используемыми при генерации ответов языковыми моделями.

[Evolution Object Storage](https://cloud.ru/docs/s3e/ug/index)Evolution Object Storage — объектное хранилище для размещения документов, из которых будет формироваться база знаний.

[Evolution ML Inference](https://cloud.ru/docs/ml-inference/ug/index)Evolution ML Inference — сервис для запуска ML-моделей в облаке.

[Huggingface](https://huggingface.co/)Huggingface — платформа для публикации и использования моделей машинного обучения.

Шаги:

1. [Создайте бакет и загрузите файл](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Создайте бакет и загрузите файл.
2. [Получите токен Huggingface](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Получите токен Huggingface.
3. [Создайте инференс для модели-эмбеддера](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Создайте инференс для модели-эмбеддера.
4. [Создайте инференс для модели-реранкера](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Создайте инференс для модели-реранкера.
5. [Создайте инференс для LLM](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Создайте инференс для LLM.
6. [Создайте базу знаний](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Создайте базу знаний.
7. [Проверьте работу базу знаний](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Проверьте работу базу знаний.

[Создайте бакет и загрузите файл](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Создайте бакет и загрузите файл.

[Получите токен Huggingface](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Получите токен Huggingface.

[Создайте инференс для модели-эмбеддера](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Создайте инференс для модели-эмбеддера.

[Создайте инференс для модели-реранкера](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Создайте инференс для модели-реранкера.

[Создайте инференс для LLM](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Создайте инференс для LLM.

[Создайте базу знаний](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Создайте базу знаний.

[Проверьте работу базу знаний](https://cloud.ru/docs/tutorials-evolution/list/topics/managed-rag__create-inference)Проверьте работу базу знаний.

## Перед началом работы

1. [Зарегистрируйтесь в личном кабинете Cloud.ru](https://cloud.ru/docs/console/ug/topics/guides__registration)Зарегистрируйтесь в личном кабинете Cloud.ru.
Если вы уже зарегистрированы, [войдите под своей учетной записью](https://cloud.ru/docs/console/ug/topics/guides__auth)войдите под своей учетной записью.
2. Убедитесь, что в личном кабинете Cloud.ru подключены сервисы [Managed RAG](https://cloud.ru/docs/rag/ug/index)Managed RAG, [ML Inference](https://cloud.ru/docs/ml-inference/ug/index)ML Inference, [Object Storage](https://cloud.ru/docs/s3e/ug/index)Object Storage.
3. Скачайте [текстовый файл faq_products.txt](https://xbox.cloud.ru/s/AiSi6scjP5YE85G)текстовый файл faq_products.txt.

[Зарегистрируйтесь в личном кабинете Cloud.ru](https://cloud.ru/docs/console/ug/topics/guides__registration)Зарегистрируйтесь в личном кабинете Cloud.ru.

Если вы уже зарегистрированы, [войдите под своей учетной записью](https://cloud.ru/docs/console/ug/topics/guides__auth)войдите под своей учетной записью.

Убедитесь, что в личном кабинете Cloud.ru подключены сервисы [Managed RAG](https://cloud.ru/docs/rag/ug/index)Managed RAG, [ML Inference](https://cloud.ru/docs/ml-inference/ug/index)ML Inference, [Object Storage](https://cloud.ru/docs/s3e/ug/index)Object Storage.

Скачайте [текстовый файл faq_products.txt](https://xbox.cloud.ru/s/AiSi6scjP5YE85G)текстовый файл faq_products.txt.

## 1. Создайте бакет и загрузите файл

1. [Создайте бакет в Object Storage](https://cloud.ru/docs/s3e/ug/topics/guides__bucket-create)Создайте бакет в Object Storage:

Укажите название бакета, например rag-inference-bucket.
Остальные параметры оставьте по умолчанию.
Нажмите Создать.
2. [Создайте папку в бакете](https://cloud.ru/docs/s3e/ug/topics/guides__file-manager_create-folder)Создайте папку в бакете со следующими параметрами:

Перейдите в бакет rag-inference-bucket.
Нажмите Создать папку.
Укажите название rag-inference-kb/ и нажмите Создать.
3. [Загрузите папку](https://cloud.ru/docs/s3e/ug/topics/guides__file-manager_upload-file)Загрузите папку текстовый файл faq_products.txt.

[Создайте бакет в Object Storage](https://cloud.ru/docs/s3e/ug/topics/guides__bucket-create)Создайте бакет в Object Storage:

1. Укажите название бакета, например rag-inference-bucket.
Остальные параметры оставьте по умолчанию.
2. Нажмите Создать.

Укажите название бакета, например rag-inference-bucket.
Остальные параметры оставьте по умолчанию.

Нажмите Создать.

[Создайте папку в бакете](https://cloud.ru/docs/s3e/ug/topics/guides__file-manager_create-folder)Создайте папку в бакете со следующими параметрами:

1. Перейдите в бакет rag-inference-bucket.
2. Нажмите Создать папку.
3. Укажите название rag-inference-kb/ и нажмите Создать.

Перейдите в бакет rag-inference-bucket.

Нажмите Создать папку.

Укажите название rag-inference-kb/ и нажмите Создать.

[Загрузите папку](https://cloud.ru/docs/s3e/ug/topics/guides__file-manager_upload-file)Загрузите папку текстовый файл faq_products.txt.

## 2. Получите токен Huggingface

1. Войдите или зарегистрируйтесь на [https://huggingface.co](https://huggingface.co/)https://huggingface.co.
2. Перейдите [в раздел Access Tokens](https://huggingface.co/settings/tokens)в раздел Access Tokens.
3. Нажмите Create new token.
4. Выберите тип Write.
5. Введите название токена, например rag_with_mlinference.
6. Нажмите Create token.
7. Скопируйте токен и сохраните его, например в блокнот.
После закрытия страницы он будет недоступен.

Войдите или зарегистрируйтесь на [https://huggingface.co](https://huggingface.co/)https://huggingface.co.

Перейдите [в раздел Access Tokens](https://huggingface.co/settings/tokens)в раздел Access Tokens.

![Раздел "Access Token"](https://cloud.ru/docs/api/cdn/tutorials-evolution/list/_images/s__managed-rag__create-inference__hf-access-tokens.png)

Нажмите Create new token.

Выберите тип Write.

Введите название токена, например rag_with_mlinference.

![Создание токена](https://cloud.ru/docs/api/cdn/tutorials-evolution/list/_images/s__managed-rag__create-inference__hf-create-token.png)

Нажмите Create token.

Скопируйте токен и сохраните его, например в блокнот.
После закрытия страницы он будет недоступен.

## 3. Создайте инференс для модели-эмбеддера

Инференс создаетcя на примере модели с Huggingface [Qwen/Qwen3-Embedding-0.6B](https://huggingface.co/Qwen/Qwen3-Embedding-0.6B)Qwen/Qwen3-Embedding-0.6B.

1. Перейдите в личный кабинет Cloud.ru, AI Factory → ML Inference.
2. На вкладке Model RUN нажмите Создать.
3. Укажите название embedder-for-rag.
4. Выберите для Runtime значение vLLM.
5. Добавьте модель.

Нажмите Добавить из Hugging Face.
В поле Репозиторий с моделью Hugging Face вставьте скопированное название модели Qwen/Qwen3-Embedding-0.6B.
Нажмите Добавить токен в Secret Management, если токен еще не добавлен.
Укажите путь, например rag_with_mlinferece.
Введите описание, например Huggingface access token.
В поле Значение секрета выберите Стандартный режим и вставьте токен Huggingface, полученный на шаге 2.
Нажмите Создать.
Токен сохранен в Secret Management.
Вернитесь к созданию инференса.
6. В поле Токен доступа в Hugging Face выберите созданный токен rag_with_mlinferece → версия 1.
7. Нажмите Добавить.
Дождитесь расчета ресурсов.
8. В поле Задача ML модели выберите Embedding — отличительная черта инференса такого типа.
9. Остальные параметры оставьте по умолчанию и нажмите Продолжить.
10. Включите опцию Не выключать модель.
11. (Опционально) Настройте масштабирование.
12. (Опционально) В настройке Аутентификация выберите сервисный аккаунт.
13. (Опционально) В настройке Логирование укажите лог‑группу.
14. Нажмите Создать.
Дождитесь, когда инференс перейдет в статус «Запущен».
15. Перейдите на вкладку Информация и скопируйте идентификатор инференса — часть публичного URL между https:// и .modelrun.
Например, в публичном URL https://12345c60-xxx-4527-xxxx-f789f789fb11.modelrun.inference.cloud.ru нужный идентификатор — 12345c60-xxx-4527-xxxx-f789f789fb11.

Перейдите в личный кабинет Cloud.ru, AI Factory → ML Inference.

На вкладке Model RUN нажмите Создать.

Укажите название embedder-for-rag.

Выберите для Runtime значение vLLM.

Добавьте модель.

1. Нажмите Добавить из Hugging Face.
2. В поле Репозиторий с моделью Hugging Face вставьте скопированное название модели Qwen/Qwen3-Embedding-0.6B.
3. Нажмите Добавить токен в Secret Management, если токен еще не добавлен.
4. Укажите путь, например rag_with_mlinferece.
5. Введите описание, например Huggingface access token.
6. В поле Значение секрета выберите Стандартный режим и вставьте токен Huggingface, полученный на шаге 2.
7. Нажмите Создать.
Токен сохранен в Secret Management.
Вернитесь к созданию инференса.

Нажмите Добавить из Hugging Face.

В поле Репозиторий с моделью Hugging Face вставьте скопированное название модели Qwen/Qwen3-Embedding-0.6B.

Нажмите Добавить токен в Secret Management, если токен еще не добавлен.

Укажите путь, например rag_with_mlinferece.

Введите описание, например Huggingface access token.

В поле Значение секрета выберите Стандартный режим и вставьте токен Huggingface, полученный на шаге 2.

Нажмите Создать.

Токен сохранен в Secret Management.
Вернитесь к созданию инференса.

В поле Токен доступа в Hugging Face выберите созданный токен rag_with_mlinferece → версия 1.

Нажмите Добавить.

Дождитесь расчета ресурсов.

В поле Задача ML модели выберите Embedding — отличительная черта инференса такого типа.

Остальные параметры оставьте по умолчанию и нажмите Продолжить.

Включите опцию Не выключать модель.

(Опционально) Настройте масштабирование.

(Опционально) В настройке Аутентификация выберите сервисный аккаунт.

(Опционально) В настройке Логирование укажите лог‑группу.

Нажмите Создать.

Дождитесь, когда инференс перейдет в статус «Запущен».

Перейдите на вкладку Информация и скопируйте идентификатор инференса — часть публичного URL между https:// и .modelrun.

Например, в публичном URL https://12345c60-xxx-4527-xxxx-f789f789fb11.modelrun.inference.cloud.ru нужный идентификатор — 12345c60-xxx-4527-xxxx-f789f789fb11.

## 4. Создайте инференс для модели-реранкера

Инференс создаетcя на примере модели с Huggingface [Qwen/Qwen3-Reranker-0.6B](https://huggingface.co/Qwen/Qwen3-Reranker-0.6B)Qwen/Qwen3-Reranker-0.6B.

1. Перейдите в личный кабинет Cloud.ru, AI Factory → ML Inference.
2. На вкладке Model RUN нажмите Создать.
3. Укажите название reranker-for-rag.
4. Выберите для Runtime значение vLLM.
5. Добавьте модель.

Нажмите Добавить из Hugging Face.
В поле Репозиторий с моделью Hugging Face вставьте скопированное название модели Qwen/Qwen3-Reranker-0.6B.
Нажмите Добавить токен в Secret management, если токен еще не добавлен.
Укажите путь, например rag_with_mlinferece.
Введите описание.
В поле Значение секрета выберите Стандартный режим и вставьте токен Huggingface, полученный на шаге 2.
Нажмите Создать.
Токен сохранен в Secret Management.
Вернитесь к созданию инференса.
6. В поле Токен доступа в Hugging Face выберите созданный токен rag_with_mlinferece → версия 1.
7. Нажмите Добавить.
Дождитесь расчета ресурсов.
8. В поле Задача ML модели выберите Score — отличительная черта инференса такого типа.
9. Остальные параметры оставьте по умолчанию и нажмите Продолжить.
10. Включите опцию Не выключать модель.
11. (Опционально) Настройте масштабирование.
12. (Опционально) В настройке Аутентификация выберите сервисный аккаунт.
13. (Опционально) В настройке Логирование укажите лог‑группу.
14. Нажмите Создать.
Дождитесь, когда инференс перейдет в статус «Запущен».
15. Перейдите на вкладку Информация и скопируйте идентификатор инференса — часть публичного URL между https:// и .modelrun.
Например, в публичном URL https://12345c60-xxx-4527-xxxx-f789f789fb11.modelrun.inference.cloud.ru нужный идентификатор — 12345c60-xxx-4527-xxxx-f789f789fb11.

Перейдите в личный кабинет Cloud.ru, AI Factory → ML Inference.

На вкладке Model RUN нажмите Создать.

Укажите название reranker-for-rag.

Выберите для Runtime значение vLLM.

Добавьте модель.

1. Нажмите Добавить из Hugging Face.
2. В поле Репозиторий с моделью Hugging Face вставьте скопированное название модели Qwen/Qwen3-Reranker-0.6B.
3. Нажмите Добавить токен в Secret management, если токен еще не добавлен.
4. Укажите путь, например rag_with_mlinferece.
5. Введите описание.
6. В поле Значение секрета выберите Стандартный режим и вставьте токен Huggingface, полученный на шаге 2.
7. Нажмите Создать.
Токен сохранен в Secret Management.
Вернитесь к созданию инференса.

Нажмите Добавить из Hugging Face.

В поле Репозиторий с моделью Hugging Face вставьте скопированное название модели Qwen/Qwen3-Reranker-0.6B.

Нажмите Добавить токен в Secret management, если токен еще не добавлен.

Укажите путь, например rag_with_mlinferece.

Введите описание.

В поле Значение секрета выберите Стандартный режим и вставьте токен Huggingface, полученный на шаге 2.

Нажмите Создать.

Токен сохранен в Secret Management.
Вернитесь к созданию инференса.

В поле Токен доступа в Hugging Face выберите созданный токен rag_with_mlinferece → версия 1.

Нажмите Добавить.

Дождитесь расчета ресурсов.

В поле Задача ML модели выберите Score — отличительная черта инференса такого типа.

Остальные параметры оставьте по умолчанию и нажмите Продолжить.

Включите опцию Не выключать модель.

(Опционально) Настройте масштабирование.

(Опционально) В настройке Аутентификация выберите сервисный аккаунт.

(Опционально) В настройке Логирование укажите лог‑группу.

Нажмите Создать.

Дождитесь, когда инференс перейдет в статус «Запущен».

Перейдите на вкладку Информация и скопируйте идентификатор инференса — часть публичного URL между https:// и .modelrun.

Например, в публичном URL https://12345c60-xxx-4527-xxxx-f789f789fb11.modelrun.inference.cloud.ru нужный идентификатор — 12345c60-xxx-4527-xxxx-f789f789fb11.

## 5. Создайте инференс для LLM

Инференс создаетcя на примере модели с Huggingface [t-tech/T-lite-it-1.0](https://huggingface.co/t-tech/T-lite-it-1.0/tree/main)t-tech/T-lite-it-1.0.

1. Перейдите в личный кабинет Cloud.ru, AI Factory → ML Inference.
2. На вкладке Model RUN нажмите Создать.
3. Укажите название llm-for-rag.
4. Выберите для Runtime значение vLLM.
5. Добавьте модель.

Нажмите Добавить из Hugging Face.
В поле Репозиторий с моделью Hugging Face вставьте скопированное название модели t-tech/T-lite-it-1.0.
Нажмите Добавить токен в Secret Management, если токен еще не добавлен.
Укажите путь, например rag_with_mlinferece.
Введите описание.
В поле Значение секрета выберите Стандартный режим и вставьте токен Huggingface, полученный на шаге 2.
Нажмите Создать.
Токен сохранен в Secret Management.
Вернитесь к созданию инференса.
6. В поле Токен доступа в Hugging Face выберите созданный токен rag_with_mlinferece → версия 1.
7. Нажмите Добавить.
Дождитесь расчета ресурсов.
8. В поле Задача ML модели выберите Generate — отличительная черта инференса такого типа.
9. Остальные параметры оставьте по умолчанию и нажмите Продолжить.
10. Включите опцию Не выключать модель.
11. (Опционально) Настройте масштабирование.
12. (Опционально) В настройке Аутентификация выберите сервисный аккаунт.
13. (Опционально) В настройке Логирование укажите лог‑группу.
14. Нажмите Создать.
Дождитесь, когда инференс перейдет в статус «Запущен».
15. Перейдите на вкладку Информация и скопируйте идентификатор инференса — часть публичного URL между https:// и .modelrun.
Например, в публичном URL https://12345c60-xxx-4527-xxxx-f789f789fb11.modelrun.inference.cloud.ru нужный идентификатор — 12345c60-xxx-4527-xxxx-f789f789fb11.

Перейдите в личный кабинет Cloud.ru, AI Factory → ML Inference.

На вкладке Model RUN нажмите Создать.

Укажите название llm-for-rag.

Выберите для Runtime значение vLLM.

Добавьте модель.

1. Нажмите Добавить из Hugging Face.
2. В поле Репозиторий с моделью Hugging Face вставьте скопированное название модели t-tech/T-lite-it-1.0.
3. Нажмите Добавить токен в Secret Management, если токен еще не добавлен.
4. Укажите путь, например rag_with_mlinferece.
5. Введите описание.
6. В поле Значение секрета выберите Стандартный режим и вставьте токен Huggingface, полученный на шаге 2.
7. Нажмите Создать.
Токен сохранен в Secret Management.
Вернитесь к созданию инференса.

Нажмите Добавить из Hugging Face.

В поле Репозиторий с моделью Hugging Face вставьте скопированное название модели t-tech/T-lite-it-1.0.

Нажмите Добавить токен в Secret Management, если токен еще не добавлен.

Укажите путь, например rag_with_mlinferece.

Введите описание.

В поле Значение секрета выберите Стандартный режим и вставьте токен Huggingface, полученный на шаге 2.

Нажмите Создать.

Токен сохранен в Secret Management.
Вернитесь к созданию инференса.

В поле Токен доступа в Hugging Face выберите созданный токен rag_with_mlinferece → версия 1.

Нажмите Добавить.

Дождитесь расчета ресурсов.

В поле Задача ML модели выберите Generate — отличительная черта инференса такого типа.

Остальные параметры оставьте по умолчанию и нажмите Продолжить.

Включите опцию Не выключать модель.

(Опционально) Настройте масштабирование.

(Опционально) В настройке Аутентификация выберите сервисный аккаунт.

(Опционально) В настройке Логирование укажите лог‑группу.

Нажмите Создать.

Дождитесь, когда инференс перейдет в статус «Запущен».

Перейдите на вкладку Информация и скопируйте идентификатор инференса — часть публичного URL между https:// и .modelrun.

Например, в публичном URL https://12345c60-xxx-4527-xxxx-f789f789fb11.modelrun.inference.cloud.ru нужный идентификатор — 12345c60-xxx-4527-xxxx-f789f789fb11.

## 6. Создайте базу знаний с использованием инференса

На этом шаге вы создадите базу знаний на основе загруженных документов и проиндексируете ее для использования с языковыми моделями.

1. В личном кабинете перейдите в AI Factory → Managed RAG.
2. Нажмите Создать базу знаний.
3. В поле Название укажите имя базы знаний, например kb-rag-with-inference.
4. При необходимости введите описание.
5. В поле Путь к папке в бакете выберите папку rag-inference-kb, в бакете Object Storage, куда вы загрузили файл faq_products.txt.
6. В поле Расширение файлов введите txt и выберите его.
7. Включите опцию Вручную настроить обработку документов и модель.
8. (Опционально) В настройке Аутентификация выберите сервисный аккаунт.
9. (Опционально) В настройке Логирование укажите лог‑группу.
10. Нажмите Продолжить.
11. Пропустите настройку экстрактора и нажмите Продолжить.
12. Выберите источник модели ML Inference.
13. В списке выберите созданный инференс embedder-for-rag.
14. Нажмите Создать.
Дождитесь завершения индексации базы знаний и ее версии — это займет несколько минут.
15. Перейдите в созданную версию базы знаний.
16. Скопируйте значения полей ID версии и ID базы знаний.

В личном кабинете перейдите в AI Factory → Managed RAG.

Нажмите Создать базу знаний.

В поле Название укажите имя базы знаний, например kb-rag-with-inference.

При необходимости введите описание.

В поле Путь к папке в бакете выберите папку rag-inference-kb, в бакете Object Storage, куда вы загрузили файл faq_products.txt.

В поле Расширение файлов введите txt и выберите его.

Включите опцию Вручную настроить обработку документов и модель.

(Опционально) В настройке Аутентификация выберите сервисный аккаунт.

(Опционально) В настройке Логирование укажите лог‑группу.

Нажмите Продолжить.

Пропустите настройку экстрактора и нажмите Продолжить.

Выберите источник модели ML Inference.

В списке выберите созданный инференс embedder-for-rag.

Нажмите Создать.

Дождитесь завершения индексации базы знаний и ее версии — это займет несколько минут.

Перейдите в созданную версию базы знаний.

Скопируйте значения полей ID версии и ID базы знаний.

## 7. Проверьте работу базы знаний

Вы можете дополнительно проверить работу с базой знаний с помощью личного кабинета или API.
Рекомендуется использовать оба способа.

1. Перейдите в созданную версию базы знаний.
2. Перейдите на вкладку Чат.
3. Включите опцию Использовать модель-реранкер.
4. В качестве источника модели‑реранкера выберите ML Inference.
5. Выберите созданный инференс reranker-for-rag.
6. В качестве Модель‑LLM выберите ML Inference и из списка выберите инференс llm-for-rag.
7. Отправьте сообщение в чате и получите ответ.

Перейдите в созданную версию базы знаний.

Перейдите на вкладку Чат.

Включите опцию Использовать модель-реранкер.

В качестве источника модели‑реранкера выберите ML Inference.

Выберите созданный инференс reranker-for-rag.

В качестве Модель‑LLM выберите ML Inference и из списка выберите инференс llm-for-rag.

Отправьте сообщение в чате и получите ответ.

## Что дальше

С этим руководством вы создали базу знаний на основе нескольких инференсов моделей.

Теперь можно [отправлять запросы к инференсу](https://cloud.ru/docs/ml-inference/ug/topics/guides__test-call)отправлять запросы к инференсу.

Узнавайте больше о прикладных сценариях и примерах решения бизнес-задач, получайте навыки управления облаком, выполняя [практические руководства](https://cloud.ru/docs/tutorials-evolution/list/index)практические руководства.
